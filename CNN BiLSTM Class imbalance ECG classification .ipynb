{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168346c-3323-4a66-b79c-572aadf7b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed242b9-d618-4831-a7e0-62f4a52cb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d093d1e",
   "metadata": {},
   "source": [
    "# 1. Environment Setup and Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29a740",
   "metadata": {},
   "source": [
    "### 1.1 Import libraries & signal data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a704b2e-3304-4062-9f85-9b0fa5e7e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "import pywt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14294dc0-1246-4e45-9f66-0429c57e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4220795-17f4-4789-8027-dd93c36ed091",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Desktop/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3'\n",
    "sampling_rate=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed1975",
   "metadata": {},
   "source": [
    "### 1.2 Metadata preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39840836-a9f9-422b-b506-5e12f000e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and convert annotation data\n",
    "metadata = pd.read_csv('ptbxl_database.csv', index_col='ecg_id')\n",
    "metadata.scp_codes = metadata.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load scp_codes (diagnosis) for each signal data\n",
    "scp_codes_df = metadata[['scp_codes']]\n",
    "print(scp_codes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ea30a-e16b-4394-8deb-61268e385582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview to see the density of each column\n",
    "msno.matrix(metadata)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59377e72-3d90-47ea-be8c-1a2a8f88ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata['scp_codes'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0b2a7-77f6-4dfd-958f-cf53064f0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "print(agg_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64eadd7-3b09-42ef-b297-680813f9fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_superclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            # only select 100% diagnosis\n",
    "            if y_dic[key] == 100: \n",
    "                tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "    \n",
    "# Apply diagnostic superclass\n",
    "metadata['diagnostic_superclass'] = metadata.scp_codes.apply(aggregate_superclass_diagnostic)\n",
    "metadata['diagnostic_superclass_len'] = metadata['diagnostic_superclass'].apply(len)\n",
    "metadata.loc[metadata.diagnostic_superclass_len >= 1, 'diagnostic_superclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee44b63c-7051-43c2-adcc-93dfe899929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_superclass = metadata['diagnostic_superclass_len'].value_counts()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "bar,ax = plt.subplots(figsize=(10,6))\n",
    "ax = sns.barplot(x=vc_superclass.values/vc_superclass.values.sum()*100., y=vc_superclass.index, ci=None, palette=\"muted\",orient='h' )\n",
    "ax.set_title(\"Diagnostic Superclass Len Distribution\", fontsize=20)\n",
    "ax.set_xlabel (\"percentage over all samples\")\n",
    "ax.set_ylabel (\"diagnostic_superclass_len\")\n",
    "for rect in ax.patches:\n",
    "    ax.text (rect.get_width(), rect.get_y() + rect.get_height() / 2,\"%.1f%%\"% rect.get_width(), weight='bold' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c17aba-1e3a-4abd-8654-241cae7b9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of single superclass data\n",
    "single_label = metadata[metadata['diagnostic_superclass_len'] == 1]\n",
    "print(single_label.shape)\n",
    "vc_single = single_label['diagnostic_superclass'].value_counts()\n",
    "plt.pie(vc_single, labels=vc_single.index, autopct='%1.1f%%')\n",
    "plt.title('Distribution of Single Superclass')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97cceb",
   "metadata": {},
   "source": [
    "### 1.3 Metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13258a5-6830-4dd6-abb5-87dec2090552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the single superclass data with 'NORM', 'STTC','CD','MI'\n",
    "single_label = single_label[single_label['diagnostic_superclass'].apply(lambda x: x != ['HYP'])]\n",
    "single_label['diagnostic_superclass']=single_label['diagnostic_superclass'].apply(lambda x: ' '.join(x))\n",
    "single_label['diagnostic_superclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921c5de-4dad-4aa2-a6a5-77a1233cecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclass= single_label.groupby(['diagnostic_superclass']).size().reset_index(name='count')\n",
    "print(superclass)\n",
    "\n",
    "# Plot a bar plot to visualize the number of ECG for each label using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=superclass, x='diagnostic_superclass', y='count')\n",
    "plt.title('Number of Each Diagnostic Superclass')\n",
    "plt.xlabel('Diagnostic Superclass')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 3000 ECG signals for each class (if less than 3000, sample all of them)\n",
    "samples = []\n",
    "for label in single_label['diagnostic_superclass'].unique():\n",
    "    # Filter the data for the current label\n",
    "    _data = single_label[single_label['diagnostic_superclass'] == label]\n",
    "    \n",
    "    # Sample 3000 rows (or fewer if there aren't enough rows) from the current label\n",
    "    _sample = _data.sample(n=min(3000, len(_data)), random_state=42)\n",
    "    \n",
    "    # Append the sampled data to the list\n",
    "    samples.append(_sample)\n",
    "\n",
    "# Concatenate all samples into a single DataFrame\n",
    "balanced_data = pd.concat(samples).reset_index(drop=True)\n",
    "\n",
    "balanced_data.groupby(['diagnostic_superclass']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2debc-8641-4e41-8d48-c1169aa7e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols =balanced_data[['age', 'sex', 'strat_fold', 'filename_lr', 'filename_hr']]\n",
    "one_hot = pd.get_dummies(balanced_data['diagnostic_superclass'], columns=['diagnostic_superclass', ], prefix='', prefix_sep='', dtype=int)\n",
    "ECG_meta=pd.concat([meta_cols, one_hot], axis=1)\n",
    "ECG_meta.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a80d6",
   "metadata": {},
   "source": [
    "### 1.4 Waveform signal display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2318b17-2291-4f5a-9a34-a3c5b5313ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ECG data according to selected metadata\n",
    "X = load_raw_data(ECG_meta, sampling_rate, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25febae0-acba-4d2e-9262-8b597265fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show one sample data for each class\n",
    "sample_num = 1\n",
    "\n",
    "for superclass in one_hot:\n",
    "    filt = ECG_meta[superclass] == 1\n",
    "    y_selected = ECG_meta.loc[filt]\n",
    "    x_selected = X[filt]\n",
    "    \n",
    "    for i in range(sample_num):\n",
    "        y_ = y_selected.iloc[i]\n",
    "        x_ = x_selected[i]\n",
    "        \n",
    "        bar, axes = plt.subplots(x_.shape[1], 1, figsize=(10,10))\n",
    "        title = \"Superclass = {}, Sex = {}, Age={}\".format(superclass, y_['sex'], y_['age'],)\n",
    "        axes[0].set_title(title, fontsize=15)\n",
    "        \n",
    "        for c in np.arange(x_.shape[1]):\n",
    "            sns.lineplot(x=np.arange(x_.shape[0]), y=x_[:, c], ax=axes[c])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4588548",
   "metadata": {},
   "source": [
    "# 2. Train-Valid-Test Set Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f82d66",
   "metadata": {},
   "source": [
    "According to the source of the dataset:https://physionet.org/content/ptb-xl/1.0.1/, there are recommended stratified 10-folds, where the same patients are kept within the same folds. Moreover, 9th fold and 10th are of higher quality, which are recommeded to be used as validation set and test set.\n",
    "\n",
    "Cross-validation Folds: recommended 10-fold train-test splits (strat_fold) obtained via stratified sampling while respecting patient assignments, i.e. all records of a particular patient were assigned to the same fold. Records in fold 9 and 10 underwent at least one human evaluation and are therefore of a particularly high label quality. We therefore propose to use folds 1-8 as training set, fold 9 as validation set and fold 10 as test set.\n",
    "Here, I will split compile fold 1-8 as train sets, fold 9 as validation set, and fold 10 as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6047d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold= balanced_data.copy()\n",
    "fold['strat_fold'] = fold['strat_fold'].map(lambda x: 'train' if x in range(1, 9) else 'validation' if x in [9] else 'test')\n",
    "fold_counts = fold.groupby(['strat_fold','diagnostic_superclass']).size().reset_index(name='count')\n",
    "print(fold_counts)\n",
    "\n",
    "# Plot a bar plot to visualize the number of ECG for each label using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=fold_counts, x='strat_fold', y='count',hue='diagnostic_superclass')\n",
    "plt.title('Distribution for Each Diagnostic Superclass')\n",
    "plt.xlabel('Diagnostic Superclass')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.legend(title='superclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964386e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of single superclass data\n",
    "vc_fold = fold['strat_fold'].value_counts()\n",
    "plt.pie(vc_fold, labels=vc_fold.index, autopct='%1.1f%%')\n",
    "plt.title('Distribution of Single Superclass')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e109cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target =  ECG_meta[['NORM', 'MI', 'STTC', 'CD']]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d76808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training-validation-testing data split\n",
    "X_train, Y_train = X[ECG_meta.strat_fold <= 8],  target[ECG_meta.strat_fold <= 8]\n",
    "X_valid, Y_valid = X[ECG_meta.strat_fold == 9],  target[ECG_meta.strat_fold == 9]\n",
    "X_test,  Y_test  = X[ECG_meta.strat_fold == 10], target[ECG_meta.strat_fold == 10]\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_valid.shape, Y_valid.shape)\n",
    "print(X_test.shape,  Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9084121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to npz file\n",
    "NUMPY_DATA_FILE = 'data.npz'\n",
    "\n",
    "save_args = {\n",
    "    'X_train': X_train.astype('float32'),\n",
    "    'X_valid': X_valid.astype('float32'),\n",
    "    'X_test':  X_test.astype('float32'),\n",
    "    'Y_train': Y_train.to_numpy().astype('float32'), \n",
    "    'Y_valid': Y_valid.to_numpy().astype('float32'),\n",
    "    'Y_test':  Y_test.to_numpy().astype('float32'),\n",
    "}\n",
    "np.savez(NUMPY_DATA_FILE, **save_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc37719",
   "metadata": {},
   "source": [
    "# 3: Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install opencv-python\n",
    "%pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08400edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586c544-8941-4d9c-b0a5-e66776370b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense,LeakyReLU\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "import cv2\n",
    "import time\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "thismodule = sys.modules[__name__]\n",
    "\n",
    "with np.load('data.npz') as data:\n",
    "    for k in data.keys():\n",
    "        setattr(thismodule, k, data[k].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9867c1",
   "metadata": {},
   "source": [
    "### 3.1 1DCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build CNN model\n",
    "def CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=10, strides=3, padding='same',input_shape = (1000,12)))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(layers.Dropout(rate=0.1))\n",
    "    model.add(layers.Dense(units=7))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(layers.Dense(units=4, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics=['accuracy', 'auc', 'precision', 'recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 summary\n",
    "model1=CNN()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 training\n",
    "history1 = model1.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_precision, val_recall= model1.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,11)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history1.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history1.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history1.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history1.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history1.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Model Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history1.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history1.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history1.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred = model1.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: 1DCNN model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, auc, precision, recall = model1.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred = model1.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: 1DCNN model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb945e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap visualization\n",
    "def plot_class_specific_confusion_matrices(y_true, y_pred, class_names):\n",
    "    num_classes = cm.shape[0]\n",
    "\n",
    "    for i in range(1,num_classes):\n",
    "        # Calculate metrics for class `i`\n",
    "        TP = cm[i, i]/np.sum(cm)\n",
    "        FP = (np.sum(cm[:, i]) - cm[i, i])/np.sum(cm)\n",
    "        FN = (np.sum(cm[i, :]) - cm[i, i])/np.sum(cm)   \n",
    "        TN = 1 - (TP + FP + FN)\n",
    "        # Create a binary confusion matrix for class `i`\n",
    "        class_cm = np.array([[TP, FP], [FN, TN]])\n",
    "\n",
    "        # Labels for the binary confusion matrix\n",
    "        labels = [\"Pred Positive\", \"Pred Negative\"]\n",
    "        tick_labels = [\"True Positive\", \"True Negative\"]\n",
    "\n",
    "        # Plot the binary confusion matrix\n",
    "        plt.figure(figsize=(4,3))\n",
    "        sns.heatmap(class_cm, annot=True, cmap='Blues',\n",
    "                    xticklabels=labels, yticklabels=tick_labels)\n",
    "        plt.title(f\"Confusion Matrix for Class {class_names[i]}\")\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.show()\n",
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701dceff",
   "metadata": {},
   "source": [
    "### 3.1.1 Random search Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b98ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hp.Choice('filters_1', values=[16, 32, 64]), kernel_size=hp.Choice('kernel_size_1', values=[3, 5, 10]), strides=3, padding='same',input_shape = (1000,12)))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=hp.Choice('filters_2', values=[16, 32, 64]), kernel_size=hp.Choice('kernel_size_2', values=[3, 5, 7]), strides=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=hp.Choice('filters_3', values=[32, 64, 128]), kernel_size=hp.Choice('kernel_size_3', values=[3, 5, 7]), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(layers.Dropout(rate=hp.Choice('dropout_rate', values=[0.1, 0.2, 0.3])))\n",
    "    model.add(layers.Dense(units=hp.Choice('units_1', values=[5,7,10])))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(layers.Dense(units=4, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics=['accuracy', 'auc', 'precision', 'recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    CNN,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=7,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=2,  # Number of times to train each model\n",
    "    directory='hyperparameter_tuning_1DCNN',\n",
    "    project_name='1dcnn_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2da273",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, Y_train, \n",
    "             epochs=10, \n",
    "             validation_data=(X_valid, Y_valid), \n",
    "             batch_size=64)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "tuned_model_1DCNN = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(f\"\"\"\n",
    "Best hyperparameters:\n",
    "Filters 1: {best_hps.get('filters_1')}\n",
    "Kernel Size 1: {best_hps.get('kernel_size_1')}\n",
    "Filters 2: {best_hps.get('filters_2')}\n",
    "Kernel Size 2: {best_hps.get('kernel_size_2')}\n",
    "Filters 3: {best_hps.get('filters_3')}\n",
    "Kernel Size 3: {best_hps.get('kernel_size_3')}\n",
    "Dense Units 1: {best_hps.get('units_1')}\n",
    "Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "\"\"\")\n",
    "tuned_model_1DCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24daf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = tuned_model_1DCNN.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_percision, val_recall = tuned_model_1DCNN.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55552d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,11)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history2.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history2.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history2.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history2.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history2.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Model Training and Validation Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history2.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history2.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history2.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred = tuned_model_1DCNN.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: tuned 1DCNN model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034041ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, auc, precision, recall = tuned_model_1DCNN.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred =tuned_model_1DCNN.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: tuned 1DCNN model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ddf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred = tuned_model_1DCNN.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Baseline Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158c06f",
   "metadata": {},
   "source": [
    "### 3.2 Bidirectional LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Bidirectional(LSTM(64), input_shape=(1000, 12)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=7))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics=['accuracy', 'auc', 'precision', 'recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed397190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=BiLSTM()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model2.fit(X_train, Y_train, epochs=5, batch_size=128, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_percision, val_recall = model2.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,6)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history3.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history3.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history3.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history3.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history3.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Model Training and Validation Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history3.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history3.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history3.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80712437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred =model2.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for BiLSTM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss, accuracy, auc, precision, recall = model2.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred =model2.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: BiLSTM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199dd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Baseline Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498cb08",
   "metadata": {},
   "source": [
    "### 3.3 CNN+BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_BiLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=10, strides=3, padding='same',input_shape = (1000,12)))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.Bidirectional((LSTM(64))))\n",
    "    model.add(Flatten())\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(units=10))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(layers.Dense(units=7, activation='relu'))\n",
    "    model.add(layers.Dense(units=4, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics=['accuracy', 'auc', 'precision', 'recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b77926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CNN_BiLSTM()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model3.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_percision, val_recall = model3.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,11)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history4.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history4.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history4.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history4.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history4.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Model Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history4.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history4.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history4.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred =model3.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for CNN+BiLSTM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss, accuracy, auc, precision, recall = model3.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred =model3.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: CNN+BiLSTM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67248f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Baseline Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b91fb0",
   "metadata": {},
   "source": [
    "### 3.3.1 Random search hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_LSTM(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hp.Choice('filters_1', values=[16, 32, 64]), kernel_size=hp.Choice('kernel_size_1', values=[3, 5, 10]), strides=3, padding='same', input_shape = (1000,12)))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=hp.Choice('filters_2', values=[16, 32, 64]), kernel_size=hp.Choice('kernel_size_2', values=[3, 5, 7]), strides=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Conv1D(filters=hp.Choice('filters_3', values=[32, 64, 128]), kernel_size=hp.Choice('kernel_size_3', values=[3, 5, 7]), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.Bidirectional(LSTM(units=hp.Choice('lstm_units', values=[20, 64, 100]))))\n",
    "    model.add(Flatten())\n",
    "    model.add(layers.Dropout(rate=hp.Choice('dropout_rate', values=[0.1, 0.2, 0.3])))\n",
    "    model.add(layers.Dense(units=10))\n",
    "    model.add(LeakyReLU(negative_slope=0.2))\n",
    "    model.add(layers.Dense(units=7, activation='relu'))\n",
    "    model.add(layers.Dense(units=4, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics=['accuracy', 'auc', 'precision', 'recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7359aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    CNN_LSTM,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=7,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=2,  # Number of times to train each model\n",
    "    directory='hyperparameter_tuning_CNNBiLSTM',\n",
    "    project_name='cnn_bilstm_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, Y_train, \n",
    "             epochs=10, \n",
    "             validation_data=(X_valid, Y_valid), \n",
    "             batch_size=64)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "tuned_model_CNNLSTM = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(f\"\"\"\n",
    "Best hyperparameters:\n",
    "Filters 1: {best_hps.get('filters_1')}\n",
    "Kernel Size 1: {best_hps.get('kernel_size_1')}\n",
    "Filters 2: {best_hps.get('filters_2')}\n",
    "Kernel Size 2: {best_hps.get('kernel_size_2')}\n",
    "Filters 3: {best_hps.get('filters_3')}\n",
    "Kernel Size 3: {best_hps.get('kernel_size_3')}\n",
    "LSTM Units 1: {best_hps.get('lstm_units')}\n",
    "Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "\"\"\")\n",
    "tuned_model_CNNLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = tuned_model_CNNLSTM.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_percision, val_recall = tuned_model_CNNLSTM.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,11)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history5.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history5.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history5.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history5.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history5.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Baseline Model Training and Validation Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history5.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history5.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history5.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Baseline Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9590b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred = tuned_model_CNNLSTM.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: tuned CNN+LSTM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73236ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss, accuracy, auc, precision, recall = tuned_model_CNNLSTM.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred =tuned_model_CNNLSTM.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: tuned 1DCNN+BiLSTM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faea2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred =tuned_model_CNNLSTM.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Baseline Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2fd1e",
   "metadata": {},
   "source": [
    "# 4. Class imbalance: SMOTE and Class Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178f1a4",
   "metadata": {},
   "source": [
    "### 4.1 Best performing model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a904510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096049f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the signals into a single feature vector for each sample. \n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "smote = SMOTE(random_state=42) #apply SMOTE to oversample the minority class. \n",
    "X_train_resampled, Y_trian_resampled = smote.fit_resample(X_train_flattened, Y_train)\n",
    "# Reshape back to the original shape\n",
    "X_train_resampled = X_train_resampled.reshape(-1, 1000, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d79e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=tuned_model_CNNLSTM\n",
    "history6 = model4.fit(X_train_resampled, Y_trian_resampled, epochs=10, batch_size=64, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_precision, vall_recall = model4.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4626ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,11)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history6.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history6.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history6.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history6.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history6.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Model Training and Validation Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history6.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history6.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history6.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred = model4.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: SMOTE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, auc, precision, recall = model4.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred =model4.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: SMOTE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred = model4.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Baseline Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173f3f2",
   "metadata": {},
   "source": [
    "### 4.2.class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "column_counts = np.sum(Y_train == 1, axis=0)\n",
    "row_counts = Y_train.shape[0]\n",
    "NORM_weight=row_counts/(4*column_counts[0])\n",
    "MI_weight=row_counts/(4*column_counts[1])\n",
    "STTC_weight=row_counts/(4*column_counts[2])\n",
    "CD_weight=row_counts/(4*column_counts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight={0:NORM_weight,1:MI_weight,2:STTC_weight,3:CD_weight}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=tuned_model_CNNLSTM\n",
    "history7 = model5.fit(X_train, Y_train, epochs=10, batch_size=64, class_weight=class_weight, validation_data=(X_valid, Y_valid))\n",
    "val_loss, val_acc, val_auc, val_percision, val_recall = model5.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca74a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array for Epochs\n",
    "epochs = np.arange(1,11)\n",
    "# Best epoch for accuracy\n",
    "best_acc_epoch = np.argmax(history7.history['val_accuracy'])\n",
    "# Best epoch for loss\n",
    "best_loss_epoch = np.argmin(history7.history['val_loss'])\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "plt.plot(epochs, history7.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(epochs, history7.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.scatter(best_acc_epoch+1, history7.history['val_accuracy'][best_acc_epoch], color='blue', label=f'Best Epoch = {best_acc_epoch+1}')\n",
    "plt.title('Model Training and Validation Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "plt.plot(epochs, history7.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(epochs, history7.history['val_loss'], label='Validation Loss', color='green')\n",
    "plt.scatter(best_loss_epoch+1, history7.history['val_loss'][best_loss_epoch], color='blue', label=f'Best Epoch = {best_loss_epoch+1}')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "# Generate predictions\n",
    "Y_pred = model5.predict(X_valid)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_valid, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_valid.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: class weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3071a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, auc, precision, recall = model5.evaluate(X_test, Y_test)\n",
    "print(f\"Loss : {loss}\")\n",
    "print(f\"Accuracy : {accuracy}\")\n",
    "print(f\"Area under the Curve (ROC) : {auc}\")\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "# Generate predictions\n",
    "Y_pred = model5.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5) # Assuming one-hot encoded labels\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "class_names = ['NORM','MI', 'STTC','CD']\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "cmp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: class weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#calculate precision,recall and F1score\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "# tranform the former label dictionary into list\n",
    "label_list = class_names\n",
    "\n",
    "# print precision, recall, f1score and he sample size for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1score, support)):\n",
    "    label = label = label_list[i]\n",
    "    print(f'{label}: Precision={p:.3f}, Recall={r:.3f}, F1 Score={f:.3f}, Support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d32951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "# Binarize The Target By One-Hot-Encoding In A OvR Fashion\n",
    "label_binarizer = LabelBinarizer().fit(Y_train)\n",
    "y_onehot_test = label_binarizer.transform(Y_test)\n",
    "n_classes = Y_test.shape[1]\n",
    "y_label = Y_test\n",
    "y_pred = model5.predict(X_test)\n",
    "\n",
    "# Plot ROC and AUC for Baseline Model Validation\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "colors = cycle([\"dodgerblue\", \"tomato\", \"goldenrod\", \"seagreen\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"Class {class_id}\",\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "        plot_chance_level=(class_id == 3),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"ROC Curve for multi-class classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e38652",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_specific_confusion_matrices(y_true, y_pred, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
